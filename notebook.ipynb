{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed1f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RESOURCES\n",
    "# https://github.com/bentrevett/pytorch-seq2seq/tree/master\n",
    "# https://github.com/Arturus/kaggle-web-traffic/blob/master/images/encoder-decoder.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d69c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from time import time\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881aca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq_length = 144\n",
    "output_seq_length = 24\n",
    "\n",
    "lr = 0.00005\n",
    "num_epochs = 100\n",
    "batch_size = 512\n",
    "hidden_size = 32\n",
    "num_gru_layers = 1\n",
    "grad_clip = 1.0\n",
    "scheduled_sampling_decay = 10\n",
    "dropout = 0.\n",
    "\n",
    "# As opposed to point-wise (assumes Gaussian)\n",
    "probabilistic = True\n",
    "\n",
    "use_attention = True\n",
    "\n",
    "target_indices = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d2fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inverse sigmoid decay from https://arxiv.org/pdf/1506.03099.pdf\n",
    "def inverse_sigmoid_decay(decay):\n",
    "    def compute(indx):\n",
    "        return decay / (decay + math.exp(indx / decay))\n",
    "    return compute\n",
    "calc_teacher_force_prob = inverse_sigmoid_decay(scheduled_sampling_decay)\n",
    "\n",
    "f'At epoch {num_epochs} teacher force prob will be {calc_teacher_force_prob(num_epochs-1)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63804e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f1f59",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b876dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TensorNormalizer:\n",
    "    ''' Expects a 2d tensor to fit and transform '''\n",
    "    def __init__(self, standardize=True):\n",
    "        self.standardize = standardize\n",
    "        # For z-score standardizing\n",
    "        self.center = None\n",
    "        self.std = None\n",
    "        # For 0 to 1 normalizing\n",
    "        self.mi = None\n",
    "        self.range = None\n",
    "    \n",
    "    def _check(self, X, been_fit=False):\n",
    "        assert len(X.shape) == 2\n",
    "        if been_fit:\n",
    "            if self.standardize: assert self.center is not None and self.std is not None\n",
    "            else: assert self.range is not None and self.mi is not None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self._check(X)\n",
    "        if self.standardize:\n",
    "            self.center = X.mean(axis=0)\n",
    "            self.std = X.std(axis=0)\n",
    "        else:\n",
    "            self.mi = X.min(axis=0)[0]\n",
    "            self.range = X.max(axis=0)[0] - self.mi\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        self._check(X, been_fit=True)\n",
    "        return (X - self.center) / self.std if self.standardize else (X - self.mi) / self.range\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self, self.transform(X)\n",
    "    \n",
    "    def inverse_transform(self, X_scaled):\n",
    "        self._check(X_scaled, been_fit=True)\n",
    "        return (X_scaled * self.std) + self.center if self.standardize else (X_scaled * self.range) + self.mi\n",
    "    \n",
    "    def set_keep_columns(self, indices):\n",
    "        if self.standardize:\n",
    "            self.center = self.center[indices]\n",
    "            self.std = self.std[indices]\n",
    "        else:\n",
    "            self.mi = self.mi[indices]\n",
    "            self.range = self.range[indices]\n",
    "    \n",
    "    @staticmethod\n",
    "    def debug():\n",
    "        # Standardize\n",
    "        original = tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float)\n",
    "        scaler, scaled = TensorNormalizer(standardize=True).fit_transform(original)\n",
    "        unscaled = scaler.inverse_transform(scaled)\n",
    "        assert torch.equal(original, unscaled)\n",
    "        # Normalize\n",
    "        original = tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float)\n",
    "        scaler, scaled = TensorNormalizer(standardize=False).fit_transform(original)\n",
    "        unscaled = scaler.inverse_transform(scaled)\n",
    "        assert torch.equal(original, unscaled)\n",
    "TensorNormalizer.debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6569493a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(device):\n",
    "    # NOTE: Minus 1 so the lagged input to the decoder coorosponds to what the *target* looked like a period before\n",
    "    period = 24 - 1\n",
    "    df = np.expand_dims(pd.read_csv(f'data.csv', index_col=0).to_numpy().transpose(1, 0), 2)\n",
    "    # Add period lag\n",
    "    lag_time_series = []\n",
    "    for time_series_indx in range(df.shape[0]):\n",
    "        time_series_i = df[time_series_indx]\n",
    "        lag = np.array([time_series_i[i - period, 0] for i in range(period, time_series_i.shape[0])])\n",
    "        lag_time_series.append(lag)\n",
    "    lag_time_series = np.expand_dims(np.stack(lag_time_series, 0), 2)\n",
    "    df = df[:, period:, :]\n",
    "    df = np.concatenate((df, lag_time_series), 2)\n",
    "    # Tensor\n",
    "    data = tensor(df, dtype=torch.float).to(device)\n",
    "    # data: (num time series, timesteps, num features)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f2966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    num_timesteps = data.shape[1]\n",
    "    train_end_indx = round(0.5 * num_timesteps)\n",
    "    train_data = data[:, : train_end_indx]\n",
    "    test_end_indx = train_end_indx + round(0.25 * num_timesteps)\n",
    "    test_data = data[:, train_end_indx : test_end_indx]\n",
    "    val_data = data[:, test_end_indx : ]\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d4009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_sequences(data, input_seq_length, output_seq_length, target_indices):\n",
    "    enc_inputs, dec_inputs, dec_targets, scalers = [], [], [], []\n",
    "    # Loop over the starting timesteps of the sequences\n",
    "    for timestep in range(data.shape[1] - (input_seq_length + output_seq_length) + 1):\n",
    "        # enc_inputs: (num time series, input seq len, num features)\n",
    "        enc_inputs_at_t = deepcopy(data[:, timestep : timestep + input_seq_length, :])\n",
    "        dec_at_t = deepcopy(data[:, timestep + input_seq_length - 1 : timestep + input_seq_length + output_seq_length, :])\n",
    "        # dec_targets: (num time series, output seq len, num features)\n",
    "        dec_inputs_at_t = deepcopy(dec_at_t[:, :-1, :])\n",
    "        # dec_targets: (num time series, output seq len, num targets)\n",
    "        dec_targets_at_t = deepcopy(dec_at_t[:, 1:, target_indices])\n",
    "        # Scale each time series separately\n",
    "        all_ts_enc_inputs, all_ts_dec_inputs, all_ts_dec_targets, all_ts_scalers = [], [], [], []\n",
    "        for ts_indx in range(enc_inputs_at_t.shape[0]):\n",
    "            ts_scaler, ts_enc_inputs = TensorNormalizer(standardize=True).fit_transform(deepcopy(enc_inputs_at_t[ts_indx]))\n",
    "            ts_dec_inputs = ts_scaler.transform(deepcopy(dec_inputs_at_t[ts_indx]))\n",
    "            ts_scaler.set_keep_columns(target_indices)\n",
    "            ts_dec_targets = ts_scaler.transform(deepcopy(dec_targets_at_t[ts_indx]))\n",
    "            all_ts_enc_inputs.append(ts_enc_inputs); all_ts_dec_inputs.append(ts_dec_inputs)\n",
    "            all_ts_dec_targets.append(ts_dec_targets); all_ts_scalers.append(ts_scaler)\n",
    "        enc_inputs.append(torch.stack(all_ts_enc_inputs))\n",
    "        dec_inputs.append(torch.stack(all_ts_dec_inputs))\n",
    "        dec_targets.append(torch.stack(all_ts_dec_targets))\n",
    "        scalers.append(np.stack(all_ts_scalers))\n",
    "    enc_inputs = torch.stack(enc_inputs); dec_inputs = torch.stack(dec_inputs); \n",
    "    dec_targets = torch.stack(dec_targets); scalers = np.stack(scalers)\n",
    "    # enc_inputs: (num seq by time, num time series, input seq len, num features)\n",
    "    # dec_inputs: (num seq by time, num time series, output seq len, num features)\n",
    "    # dec_targets: (num seq by time, num time series, output seq len, num targets)\n",
    "    # scalers: (num seq by time, num time series)\n",
    "    return {'enc_inputs': enc_inputs, 'dec_inputs': dec_inputs, 'dec_targets': dec_targets, 'scalers': scalers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_series_identifier_feature(data, device):\n",
    "    # Add time series categorical identifier\n",
    "    num_time_series = float(data['enc_inputs'].shape[1])\n",
    "    def add_column(data_element):\n",
    "        new_column = []\n",
    "        for time_series_indx in range(data_element.shape[1]):\n",
    "            time_series_identifier = time_series_indx / num_time_series\n",
    "            time_series_identifier = torch.full((data_element.shape[0], data_element.shape[2], 1), time_series_identifier).to(device)\n",
    "            new_column.append(time_series_identifier)\n",
    "        new_column = torch.stack(new_column, dim=1)\n",
    "        return torch.cat((data_element, new_column), dim=3)\n",
    "    data['enc_inputs'] = add_column(data['enc_inputs'])\n",
    "    data['dec_inputs'] = add_column(data['dec_inputs'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4998c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reshape_data(data):\n",
    "    # data: (num time series)\n",
    "    for k, v in data.items():\n",
    "        if k == 'scalers':\n",
    "            data[k] = v.reshape(-1)\n",
    "        else:\n",
    "            data[k] = v.reshape(-1, v.shape[2], v.shape[3])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0caa3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "data = load_data(device)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9345ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split into train/val/test\n",
    "data_splits = split_data(data)\n",
    "data_splits[0].shape, data_splits[1].shape, data_splits[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a1dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the sequences\n",
    "data_splits = create_sequences(data_splits[0], input_seq_length, output_seq_length, target_indices), \\\n",
    "               create_sequences(data_splits[1], input_seq_length, output_seq_length, target_indices), \\\n",
    "               create_sequences(data_splits[2], input_seq_length, output_seq_length, target_indices)\n",
    "data_splits[0]['enc_inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time series indentifier (for multiple time series training)\n",
    "data_splits = add_time_series_identifier_feature(data_splits[0], device), \\\n",
    "                    add_time_series_identifier_feature(data_splits[1], device), \\\n",
    "                        add_time_series_identifier_feature(data_splits[2], device)\n",
    "data_splits[0]['enc_inputs'].shape, data_splits[0]['dec_inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0509d30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reshape to stack different time series\n",
    "train_data, val_data, test_data = reshape_data(data_splits[0]), reshape_data(data_splits[1]), reshape_data(data_splits[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eddce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data['enc_inputs'].shape, val_data['enc_inputs'].shape, test_data['enc_inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e1ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data['enc_inputs'].shape, train_data['dec_inputs'].shape, train_data['dec_targets'].shape, train_data['scalers'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e75dfb",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d501cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def layer_init(layer, w_scale=1.0):\n",
    "    nn.init.kaiming_uniform_(layer.weight.data)\n",
    "    layer.weight.data.mul_(w_scale)\n",
    "    nn.init.constant_(layer.bias.data, 0.)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5392d9de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, enc_feature_size, hidden_size, num_gru_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(enc_feature_size, hidden_size, num_gru_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # inputs: (batch size, input seq len, num enc features)\n",
    "        output, hidden = self.gru(inputs)\n",
    "            \n",
    "        # output: (batch size, input seq len, hidden size)\n",
    "        # hidden: (num gru layers, batch size, hidden size)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder superclass whose forward is called by Seq2Seq but other methods filled out by subclasses\n",
    "class DecoderBase(nn.Module):\n",
    "    def __init__(self, device, dec_target_size, target_indices, dist_size, probabilistic):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.target_indices = target_indices\n",
    "        self.target_size = dec_target_size\n",
    "        self.dist_size = dist_size\n",
    "        self.probabilistic = probabilistic\n",
    "    \n",
    "    # Have to run one step at a time unlike with the encoder since sometimes not teacher forcing\n",
    "    def run_single_recurrent_step(self, inputs, hidden, enc_outputs):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def forward(self, inputs, hidden, enc_outputs, teacher_force_prob=None):\n",
    "        # inputs: (batch size, output seq length, num dec features)\n",
    "        # hidden: (num gru layers, batch size, hidden dim), ie the last hidden state\n",
    "        # enc_outputs: (batch size, input seq len, hidden size)\n",
    "        \n",
    "        batch_size, dec_output_seq_length, _ = inputs.shape\n",
    "        \n",
    "        # Store decoder outputs\n",
    "        # outputs: (batch size, output seq len, num targets, num dist params)\n",
    "        outputs = torch.zeros(batch_size, dec_output_seq_length, self.target_size, dist_size, dtype=torch.float).to(self.device)\n",
    "\n",
    "        # curr_input: (batch size, 1, num dec features)\n",
    "        curr_input = inputs[:, 0:1, :]\n",
    "        \n",
    "        for t in range(dec_output_seq_length):\n",
    "            # dec_output: (batch size, 1, num targets, num dist params)\n",
    "            # hidden: (num gru layers, batch size, hidden size)\n",
    "            dec_output, hidden = self.run_single_recurrent_step(curr_input, hidden, enc_outputs)\n",
    "            # Save prediction\n",
    "            outputs[:, t:t+1, :, :] = dec_output\n",
    "            # dec_output: (batch size, 1, num targets)\n",
    "            dec_output = Seq2Seq.sample_from_output(dec_output)\n",
    "            \n",
    "            # If teacher forcing, use target from this timestep as next input o.w. use prediction\n",
    "            teacher_force = random.random() < teacher_force_prob if teacher_force_prob is not None else False\n",
    "            \n",
    "            curr_input = inputs[:, t:t+1, :].clone()\n",
    "            if not teacher_force:\n",
    "                curr_input[:, :, self.target_indices] = dec_output\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3428ceb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DecoderVanilla(DecoderBase):\n",
    "    def __init__(self, dec_feature_size, dec_target_size, hidden_size, \n",
    "                 num_gru_layers, target_indices, dropout, dist_size,\n",
    "                 probabilistic, device):\n",
    "        super().__init__(device, dec_target_size, target_indices, dist_size, probabilistic)\n",
    "        self.gru = nn.GRU(dec_feature_size, hidden_size, num_gru_layers, batch_first=True, dropout=dropout)\n",
    "        self.out = layer_init(nn.Linear(hidden_size + dec_feature_size, dec_target_size * dist_size))\n",
    "    \n",
    "    def run_single_recurrent_step(self, inputs, hidden, enc_outputs):\n",
    "        # inputs: (batch size, 1, num dec features)\n",
    "        # hidden: (num gru layers, batch size, hidden size)\n",
    "        \n",
    "        output, hidden = self.gru(inputs, hidden)\n",
    "        output = self.out(torch.cat((output, inputs), dim=2))\n",
    "        output = output.reshape(output.shape[0], output.shape[1], self.target_size, self.dist_size)\n",
    "        \n",
    "        # output: (batch size, 1, num targets, num dist params)\n",
    "        # hidden: (num gru layers, batch size, hidden size)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2cca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_gru_layers):\n",
    "        super().__init__()\n",
    "        # NOTE: the hidden size for the output of attn (and input of v) can actually be any number  \n",
    "        # Also, using two layers allows for a non-linear act func inbetween\n",
    "        self.attn = nn.Linear(2 * hidden_size, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "    \n",
    "    def forward(self, decoder_hidden_final_layer, encoder_outputs):\n",
    "        # decoder_hidden_final_layer: (batch size, hidden size)\n",
    "        # encoder_outputs: (batch size, input seq len, hidden size)\n",
    "        \n",
    "        # Repeat decoder hidden state input seq len times\n",
    "        hidden = decoder_hidden_final_layer.unsqueeze(1).repeat(1, encoder_outputs.shape[1], 1)\n",
    "        \n",
    "        # Compare decoder hidden state with each encoder output using a learnable tanh layer\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        \n",
    "        # Then compress into single values for each comparison (energy)\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        # Then softmax so the weightings add up to 1\n",
    "        weightings = F.softmax(attention, dim=1)\n",
    "                \n",
    "        # weightings: (batch size, input seq len)\n",
    "        return weightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560d01b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DecoderWithAttention(DecoderBase):\n",
    "    def __init__(self, dec_feature_size, dec_target_size, hidden_size, \n",
    "                 num_gru_layers, target_indices, dropout, dist_size,\n",
    "                 probabilistic, device):\n",
    "        super().__init__(device, dec_target_size, target_indices, dist_size, probabilistic)\n",
    "        self.attention_model = Attention(hidden_size, num_gru_layers)\n",
    "        # GRU takes previous timestep target and weighted sum of encoder hidden states\n",
    "        self.gru = nn.GRU(dec_feature_size + hidden_size, hidden_size, num_gru_layers, batch_first=True, dropout=dropout)\n",
    "        # Output layer takes decoder hidden state output, weighted sum and decoder input\n",
    "        # NOTE: Feeding decoder input into the output layer essentially acts as a skip connection\n",
    "        self.out = layer_init(nn.Linear(hidden_size + hidden_size + dec_feature_size, dec_target_size * dist_size))\n",
    "\n",
    "    def run_single_recurrent_step(self, inputs, hidden, enc_outputs):\n",
    "        # inputs: (batch size, 1, num dec features)\n",
    "        # hidden: (num gru layers, batch size, hidden size)\n",
    "        # enc_outputs: (batch size, input seq len, hidden size)\n",
    "        \n",
    "        # Get attention weightings\n",
    "        # weightings: (batch size, input seq len)\n",
    "        weightings = self.attention_model(hidden[-1], enc_outputs)\n",
    "        \n",
    "        # Then compute weighted sum\n",
    "        # weighted_sum: (batch size, 1, hidden size)\n",
    "        weighted_sum = torch.bmm(weightings.unsqueeze(1), enc_outputs)\n",
    "                \n",
    "        # Then input into GRU\n",
    "        # gru inputs: (batch size, 1, num dec features + hidden size)\n",
    "        # output: (batch size, 1, hidden size)\n",
    "        output, hidden = self.gru(torch.cat((inputs, weighted_sum), dim=2), hidden)\n",
    "            \n",
    "        # Get prediction\n",
    "        # out input: (batch size, 1, hidden size + hidden size + num targets)\n",
    "        output = self.out(torch.cat((output, weighted_sum, inputs), dim=2))\n",
    "        output = output.reshape(output.shape[0], output.shape[1], self.target_size, self.dist_size)\n",
    "        \n",
    "        # output: (batch size, 1, num targets, num dist params)\n",
    "        # hidden: (num gru layers, batch size, hidden size)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5600804e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, lr, grad_clip, probabilistic):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        self.opt = torch.optim.Adam(self.parameters(), lr)\n",
    "        self.loss_func = nn.GaussianNLLLoss() if probabilistic else nn.L1Loss()\n",
    "        self.grad_clip = grad_clip\n",
    "\n",
    "        self.probabilistic = probabilistic\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_smape(prediction, target):\n",
    "        return torch.mean(torch.abs(prediction - target) / ((torch.abs(target) + torch.abs(prediction)) / 2. + 1e-8)) * 100.\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_dist_params(output):\n",
    "        mu = output[:, :, :, 0]\n",
    "        # softplus to constrain to positive\n",
    "        sigma = F.softplus(output[:, :, :, 1])\n",
    "        return mu, sigma\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_from_output(output):\n",
    "        # in - output: (batch size, dec seq len, num targets, num dist params)\n",
    "        # out - output: (batch size, dec seq len, num targets)\n",
    "        if output.shape[-1] > 1:  # probabilistic can be assumed\n",
    "            mu, sigma = Seq2Seq.get_dist_params(output)\n",
    "            return torch.normal(mu, sigma)\n",
    "        # No sample just reshape if pointwise\n",
    "        return output.squeeze(-1)\n",
    "    \n",
    "    def forward(self, enc_inputs, dec_inputs, teacher_force_prob=None):\n",
    "        # enc_inputs: (batch size, input seq length, num enc features)\n",
    "        # dec_inputs: (batch size, output seq length, num dec features)\n",
    "        \n",
    "        # enc_outputs: (batch size, input seq len, hidden size)\n",
    "        # hidden: (num gru layers, batch size, hidden dim), ie the last hidden state\n",
    "        enc_outputs, hidden = self.encoder(enc_inputs)\n",
    "        \n",
    "        # outputs: (batch size, output seq len, num targets, num dist params)\n",
    "        outputs = self.decoder(dec_inputs, hidden, enc_outputs, teacher_force_prob)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "    def compute_loss(self, prediction, target, override_func=None):\n",
    "        # prediction: (batch size, dec seq len, num targets, num dist params)\n",
    "        # target: (batch size, dec seq len, num targets)\n",
    "        if self.probabilistic:\n",
    "            mu, sigma = Seq2Seq.get_dist_params(prediction)\n",
    "            var = sigma ** 2\n",
    "            loss = self.loss_func(mu, target, var)\n",
    "        else:\n",
    "            loss = self.loss_func(prediction.squeeze(-1), target)\n",
    "        return loss if self.training else loss.item()\n",
    "    \n",
    "    def optimize(self, prediction, target):\n",
    "        # prediction & target: (batch size, seq len, output dim)\n",
    "        self.opt.zero_grad()\n",
    "        loss = self.compute_loss(prediction, target)\n",
    "        loss.backward()\n",
    "        if self.grad_clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.parameters(), self.grad_clip)\n",
    "        self.opt.step()\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f8bfa",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4792c72b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# New generator every epoch\n",
    "def batch_generator(data, batch_size, unscale=False):\n",
    "    enc_inputs, dec_inputs, dec_targets, scalers = \\\n",
    "        data['enc_inputs'], data['dec_inputs'], data['dec_targets'], data['scalers']\n",
    "    indices = torch.randperm(enc_inputs.shape[0])\n",
    "    for i in range(0, len(indices), batch_size):\n",
    "        batch_indices = indices[i : i + batch_size]\n",
    "        batch_enc_inputs = enc_inputs[batch_indices]\n",
    "        batch_dec_inputs = dec_inputs[batch_indices]\n",
    "        batch_dec_targets = dec_targets[batch_indices]\n",
    "        batch_scalers = None\n",
    "        if unscale:\n",
    "            batch_scalers = scalers[batch_indices]\n",
    "            # Weird np and torch behavior if batch size is 1\n",
    "            if isinstance(batch_scalers, TensorNormalizer): batch_scalers = np.array([batch_scalers])\n",
    "        # No remainder\n",
    "        if batch_enc_inputs.shape[0] < batch_size:\n",
    "            break\n",
    "        yield batch_enc_inputs, batch_dec_inputs, batch_dec_targets, batch_scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b34a7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_data, batch_size, teacher_force_prob):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0.\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_enc_inputs, batch_dec_inputs, batch_dec_targets, _ in batch_generator(train_data, batch_size):\n",
    "        output = model(batch_enc_inputs, batch_dec_inputs, teacher_force_prob)\n",
    "        loss = model.optimize(output, batch_dec_targets)\n",
    "        \n",
    "        epoch_loss += loss\n",
    "        num_batches += 1\n",
    "    return epoch_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243fd123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, val_data, batch_size):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0.\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_enc_inputs, batch_dec_inputs, batch_dec_targets, _ in batch_generator(val_data, batch_size):\n",
    "            output = model(batch_enc_inputs, batch_dec_inputs)\n",
    "            loss = model.compute_loss(output, batch_dec_targets)\n",
    "\n",
    "            epoch_loss += loss\n",
    "            num_batches += 1\n",
    "        \n",
    "    return epoch_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b253eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist_size = 2 if probabilistic else 1\n",
    "enc_feature_size = train_data['enc_inputs'].shape[-1]\n",
    "dec_feature_size = train_data['dec_inputs'].shape[-1]\n",
    "dec_target_size = train_data['dec_targets'].shape[-1]\n",
    "\n",
    "encoder = Encoder(enc_feature_size, hidden_size, num_gru_layers, dropout)\n",
    "decoder_args = (dec_feature_size, dec_target_size, hidden_size, num_gru_layers, target_indices, dropout, dist_size, probabilistic, device)\n",
    "decoder = DecoderWithAttention(*decoder_args) if use_attention else DecoderVanilla(*decoder_args)\n",
    "seq2seq = Seq2Seq(encoder, decoder, lr, grad_clip, probabilistic).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a95a7a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_val, best_model = float('inf'), None\n",
    "for epoch in range(num_epochs):\n",
    "    start_t = time()\n",
    "    teacher_force_prob = calc_teacher_force_prob(epoch)\n",
    "    train_loss = train(seq2seq, train_data, batch_size, teacher_force_prob)\n",
    "    val_loss = evaluate(seq2seq, val_data, batch_size)\n",
    "\n",
    "    new_best_val = False\n",
    "    if val_loss < best_val:\n",
    "        new_best_val = True\n",
    "        best_val = val_loss\n",
    "        best_model = deepcopy(seq2seq)\n",
    "    print(f'Epoch {epoch+1} => Train loss: {train_loss:.5f},',\n",
    "          f'Val: {val_loss:.5f},',\n",
    "          f'Teach: {teacher_force_prob:.2f},',\n",
    "          f'Took {(time() - start_t):.1f} s{\"      (NEW BEST)\" if new_best_val else \"\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e58cbb5",
   "metadata": {},
   "source": [
    "# Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216056a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_eval = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6c4d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baselines & Best Model\n",
    "\n",
    "best_model.eval()\n",
    "\n",
    "mean_losses, norm_losses, repeat_losses, trained_model_losses = [], [], [], []\n",
    "for batch_enc_inputs, batch_dec_inputs, batch_dec_targets, _ in batch_generator(data_to_eval, 32):\n",
    "\n",
    "    # Inputs mean baseline\n",
    "    mean_baseline_preds = torch.repeat_interleave(batch_enc_inputs[:, :, target_indices].mean(axis=1, keepdims=True), data_to_eval['dec_targets'].shape[1], 1).unsqueeze(-1)\n",
    "    if probabilistic:\n",
    "        stds = torch.zeros(mean_baseline_preds.shape, dtype=torch.float).to(device)\n",
    "        mean_baseline_preds = torch.cat((mean_baseline_preds, stds), dim=3)\n",
    "    mean_loss = best_model.compute_loss(mean_baseline_preds, batch_dec_targets)\n",
    "\n",
    "    # Normal dist from inputs mean and std\n",
    "    test_inputs = batch_enc_inputs[:, :, target_indices]\n",
    "    test_inputs_mean = torch.repeat_interleave(test_inputs.mean(axis=1, keepdims=True), batch_dec_targets.shape[1], 1).unsqueeze(-1)\n",
    "    test_inputs_std = torch.repeat_interleave(test_inputs.std(axis=1, keepdims=True), batch_dec_targets.shape[1], 1).unsqueeze(-1)\n",
    "    if probabilistic:\n",
    "        norm_baseline_preds = torch.cat((test_inputs_mean, test_inputs_std), dim=3)\n",
    "    else:\n",
    "        norm_baseline_preds = torch.normal(test_inputs_mean, test_inputs_std)\n",
    "    norm_loss = best_model.compute_loss(norm_baseline_preds, batch_dec_targets)\n",
    "\n",
    "    # Repeat last input\n",
    "    repeat_baseline_preds = torch.repeat_interleave(batch_enc_inputs[:, -1:, target_indices], batch_dec_targets.shape[1], 1).unsqueeze(-1)\n",
    "    if probabilistic:\n",
    "        stds = torch.zeros(repeat_baseline_preds.shape, dtype=torch.float).to(device)\n",
    "        repeat_baseline_preds = torch.cat((repeat_baseline_preds, stds), dim=3)\n",
    "    repeat_loss = best_model.compute_loss(repeat_baseline_preds, batch_dec_targets)\n",
    "\n",
    "    # Best model\n",
    "    outputs = best_model(batch_enc_inputs, batch_dec_inputs)\n",
    "    trained_model_loss = best_model.compute_loss(outputs, batch_dec_targets)\n",
    "\n",
    "    mean_losses.append(mean_loss); norm_losses.append(norm_loss)\n",
    "    repeat_losses.append(repeat_loss); trained_model_losses.append(trained_model_loss)\n",
    "np.mean(mean_losses), np.mean(norm_losses), np.mean(repeat_losses), np.mean(trained_model_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663f614",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "target_to_vis = 0\n",
    "num_vis = 10\n",
    "num_rollouts = 50 if probabilistic else 1\n",
    "\n",
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_enc_inputs, batch_dec_inputs, batch_dec_targets, scalers = next(batch_generator(data_to_eval, num_vis, unscale=True))\n",
    "\n",
    "    outputs = []\n",
    "    for r in range(num_rollouts):\n",
    "        outputs.append(Seq2Seq.sample_from_output(best_model(batch_enc_inputs, batch_dec_inputs)))\n",
    "    outputs = torch.stack(outputs, dim=1)\n",
    "\n",
    "for indx in range(batch_enc_inputs.shape[0]):\n",
    "    scaler = scalers[indx]\n",
    "    sample_enc_inputs, sample_dec_inputs, sample_dec_targets = \\\n",
    "        scaler.inverse_transform(batch_enc_inputs[indx])[:, target_to_vis].cpu().numpy().tolist(),\\\n",
    "            scaler.inverse_transform(batch_dec_inputs[indx])[:, target_to_vis].cpu().numpy().tolist(), \\\n",
    "                scaler.inverse_transform(batch_dec_targets[indx])[:, target_to_vis].cpu().numpy().tolist()\n",
    "    output_rollouts = []\n",
    "    for output_rollout in outputs[indx]:\n",
    "        output_rollouts.append(scaler.inverse_transform(output_rollout)[:, target_to_vis].cpu().numpy().tolist())\n",
    "    output_rollouts = np.array(output_rollouts)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    x = list(range(len(sample_enc_inputs) + len(sample_dec_targets)))\n",
    "    # Plot inputs\n",
    "    plt.plot(x, sample_enc_inputs + sample_dec_targets)\n",
    "    # Plot median\n",
    "    output_x = list(range(len(sample_enc_inputs), len(x)))\n",
    "    plt.plot(output_x, np.median(output_rollouts, axis=0))\n",
    "    # Plot quantiles\n",
    "    plt.fill_between(\n",
    "        output_x,\n",
    "        np.quantile(output_rollouts, 0.05, axis=0), \n",
    "        np.quantile(output_rollouts, 0.95, axis=0), \n",
    "        alpha=0.3, \n",
    "        interpolate=True\n",
    "    )\n",
    "    plt.gca().set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a8fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
